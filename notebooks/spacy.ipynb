{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Dell/.cache/huggingface/datasets/json/default-aef40b4b132ab43c/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd3e1570888401f899df94ffd9552fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Dell/.cache/huggingface/datasets/json/default-f4584a93bbbd7e8a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d1a1e46d9d04380ade62a177d3c00d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Dell\\.cache\\huggingface\\datasets\\json\\default-aef40b4b132ab43c\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-bd9e74115e31da9a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Dell\\.cache\\huggingface\\datasets\\json\\default-f4584a93bbbd7e8a\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-31308b93ec420624.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['annotations', 'text'],\n",
       "        num_rows: 10995\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['annotations', 'text'],\n",
       "        num_rows: 1074\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils import get_hf_dataset\n",
    "dataset = get_hf_dataset()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Dell\\.cache\\huggingface\\datasets\\json\\default-aef40b4b132ab43c\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-5274ff6e7b61f37b.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Dell\\.cache\\huggingface\\datasets\\json\\default-f4584a93bbbd7e8a\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-bd2f0917eeea4537.arrow\n"
     ]
    }
   ],
   "source": [
    "from utils import parse_to_ner\n",
    "dataset_ner = parse_to_ner(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Dell\\.cache\\huggingface\\datasets\\json\\default-aef40b4b132ab43c\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-c3fc1fbe7918877a.arrow\n"
     ]
    }
   ],
   "source": [
    "from utils import cast_ner_labels_to_int\n",
    "casted = cast_ner_labels_to_int(dataset_ner['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotations': [{'from_name': 'label',\n",
       "   'id': 'C8HPTIM1',\n",
       "   'to_name': 'text',\n",
       "   'type': 'labels',\n",
       "   'value': {'end': 103,\n",
       "    'labels': ['ORG'],\n",
       "    'start': 90,\n",
       "    'text': 'Hongkong Bank'}},\n",
       "  {'from_name': 'label',\n",
       "   'id': 'KOWE3RAM',\n",
       "   'to_name': 'text',\n",
       "   'type': 'labels',\n",
       "   'value': {'end': 278,\n",
       "    'labels': ['ORG'],\n",
       "    'start': 267,\n",
       "    'text': 'Rahul & Co.'}}],\n",
       " 'text': \"\\n\\n(7) On specific query by the Bench about an entry of Rs. 1,31,37,500 on deposit side of Hongkong Bank account of which a photo copy is appearing at p. 40 of assessee's paper book, learned authorised representative submitted that it was related to loan from broker, Rahul & Co. on the basis of his submission a necessary mark is put by us on that photo copy.\"}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Dell/.cache/huggingface/datasets/json/default-aef40b4b132ab43c/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23014b156f2b458ca2b1925f329db07a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/Dell/.cache/huggingface/datasets/json/default-f4584a93bbbd7e8a/0.0.0/fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006ffdfb194c43e0ae4fe56ed32acd60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Dell\\.cache\\huggingface\\datasets\\json\\default-aef40b4b132ab43c\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-bd9e74115e31da9a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Dell\\.cache\\huggingface\\datasets\\json\\default-f4584a93bbbd7e8a\\0.0.0\\fe5dd6ea2639a6df622901539cb550cf8797e5a6b2dd7af1cf934bed8e233e6e\\cache-31308b93ec420624.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"\\n\\n(7) On specific query by the Bench about an entry of Rs. 1,31,37,500 on deposit side of Hongkong Bank account of which a photo copy is appearing at p. 40 of assessee's paper book, learned authorised representative submitted that it was related to loan from broker, Rahul & Co. on the basis of his submission a necessary mark is put by us on that photo copy.\",\n",
       " {'entities': [(90, 103, 'ORG'), (267, 278, 'ORG')]})"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spacy train data\n",
    "from utils import get_hf_dataset, parse_to_ner, cast_ner_labels_to_int\n",
    "\n",
    "dataset = get_hf_dataset()\n",
    "\n",
    "TRAIN_DATA = []\n",
    "\n",
    "for example in dataset['train']:\n",
    "    text = example['text']\n",
    "    entities = []\n",
    "    for annotation in example['annotations']:\n",
    "        result = annotation['value']\n",
    "        start = result['start']\n",
    "        end = result['end']\n",
    "        label = result['labels'][0]\n",
    "        entities.append((start, end, label))\n",
    "    TRAIN_DATA.append((text, {\"entities\": entities}))\n",
    "\n",
    "TRAIN_DATA[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "model = \"en_core_web_sm\"\n",
    "output_dir=Path(\"../spacy/output\")\n",
    "n_iter=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'en_core_web_sm'\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(model)  \n",
    "print(\"Loaded model '%s'\" % model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ner.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CARDINAL',\n",
       " 'CASE_NUMBER',\n",
       " 'COURT',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'JUDGE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LAWYER',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'OTHER_PERSON',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PETITIONER',\n",
       " 'PRECEDENT',\n",
       " 'PRODUCT',\n",
       " 'PROVISION',\n",
       " 'QUANTITY',\n",
       " 'RESPONDENT',\n",
       " 'STATUTE',\n",
       " 'TIME',\n",
       " 'WITNESS',\n",
       " 'WORK_OF_ART')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "\n",
    "ner.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CASE_NUMBER',\n",
       " 'COURT',\n",
       " 'DATE',\n",
       " 'GPE',\n",
       " 'JUDGE',\n",
       " 'LAWYER',\n",
       " 'ORG',\n",
       " 'OTHER_PERSON',\n",
       " 'PETITIONER',\n",
       " 'PRECEDENT',\n",
       " 'PROVISION',\n",
       " 'RESPONDENT',\n",
       " 'STATUTE',\n",
       " 'WITNESS'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print all labels from traindata\n",
    "labels = set()\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        labels.add(ent[2])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [06:39<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[89], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m     doc \u001b[39m=\u001b[39m nlp\u001b[39m.\u001b[39mmake_doc(text)\n\u001b[0;32m     11\u001b[0m     example \u001b[39m=\u001b[39m Example\u001b[39m.\u001b[39mfrom_dict(doc, annotations)\n\u001b[1;32m---> 12\u001b[0m     nlp\u001b[39m.\u001b[39;49mupdate(\n\u001b[0;32m     13\u001b[0m         [example],\n\u001b[0;32m     14\u001b[0m         drop\u001b[39m=\u001b[39;49m\u001b[39m0.5\u001b[39;49m,\n\u001b[0;32m     15\u001b[0m         sgd\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m     16\u001b[0m         losses\u001b[39m=\u001b[39;49mlosses\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(losses)\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\language.py:1155\u001b[0m, in \u001b[0;36mLanguage.update\u001b[1;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[39mfor\u001b[39;00m name, proc \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpipeline:\n\u001b[0;32m   1153\u001b[0m     \u001b[39m# ignore statements are used here because mypy ignores hasattr\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(proc, \u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1155\u001b[0m         proc\u001b[39m.\u001b[39mupdate(examples, sgd\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, losses\u001b[39m=\u001b[39mlosses, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcomponent_cfg[name])  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m   1156\u001b[0m     \u001b[39mif\u001b[39;00m sgd \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mNone\u001b[39;00m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   1157\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1158\u001b[0m             name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m exclude\n\u001b[0;32m   1159\u001b[0m             \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(proc, ty\u001b[39m.\u001b[39mTrainableComponent)\n\u001b[0;32m   1160\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mis_trainable\n\u001b[0;32m   1161\u001b[0m             \u001b[39mand\u001b[39;00m proc\u001b[39m.\u001b[39mmodel \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, \u001b[39mFalse\u001b[39;00m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m   1162\u001b[0m         ):\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx:418\u001b[0m, in \u001b[0;36mspacy.pipeline.transition_parser.Parser.update\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\ml\\parser_model.pyx:321\u001b[0m, in \u001b[0;36mspacy.ml.parser_model.step_forward.backprop_parser_step\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\layers\\linear.py:44\u001b[0m, in \u001b[0;36mforward.<locals>.backprop\u001b[1;34m(dY)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackprop\u001b[39m(dY: OutT) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m InT:\n\u001b[0;32m     43\u001b[0m     model\u001b[39m.\u001b[39minc_grad(\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m, dY\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m))\n\u001b[1;32m---> 44\u001b[0m     model\u001b[39m.\u001b[39minc_grad(\u001b[39m\"\u001b[39m\u001b[39mW\u001b[39m\u001b[39m\"\u001b[39m, model\u001b[39m.\u001b[39;49mops\u001b[39m.\u001b[39;49mgemm(dY, X, trans1\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[0;32m     45\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mops\u001b[39m.\u001b[39mgemm(dY, W)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from spacy.training.example import Example\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.create_optimizer()\n",
    "    for itn in tqdm(range(n_iter)):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        for text, annotations in TRAIN_DATA:\n",
    "            doc = nlp.make_doc(text)\n",
    "            example = Example.from_dict(doc, annotations)\n",
    "            nlp.update(\n",
    "                [example],\n",
    "                drop=0.5,\n",
    "                sgd=optimizer,\n",
    "                losses=losses,\n",
    "                \n",
    "            )\n",
    "        print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
