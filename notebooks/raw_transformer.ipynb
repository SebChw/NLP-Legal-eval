{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/indianlegalbert/OPEN_SOURCED_FILES/NER/NER_TRAIN.zip\n",
    "!wget https://storage.googleapis.com/indianlegalbert/OPEN_SOURCED_FILES/NER/NER_DEV.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!unzip NER_DEV.zip\n",
    "!unzip NER_TRAIN.zip"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "from transformers.tokenization_utils_base import TokenSpan\n",
    "from tqdm import tqdm\n",
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LABELS = [\"COURT\",  \"PETITIONER\", \"RESPONDENT\", \"JUDGE\", \"LAWYER\", \"DATE\", \"ORG\", \"GPE\", \"STATUTE\", \"PROVISION\", \"PRECEDENT\", \"CASE_NUMBER\", \"WITNESS\", \"OTHER_PERSON\"]\n",
    "LABELS = [\"O\"] + [\"B-\"+label for label in LABELS] + [\"I-\"+label for label in LABELS]\n",
    "id2label = {i:label for i,label in enumerate(LABELS)}\n",
    "label2id = {label:id for id, label in id2label.items()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_and_ner(text, named_entities):\n",
    "  #! Please leave this function as an example why not to use COLAB! TEXT variable is not used here.\n",
    "  tokens = tokenizer.encode_plus(text, return_offsets_mapping=True)\n",
    "  offsets = tokens['offset_mapping']\n",
    "  # Initialize the label list\n",
    "  labels = [label2id[\"O\"]] * len(tokens['input_ids'])\n",
    "\n",
    "  # Iterate over each named entity\n",
    "  for named_entity in named_entities:\n",
    "      start_char = named_entity[\"start\"]\n",
    "      end_char = named_entity[\"end\"]\n",
    "      # Find the nearest token boundaries to the named entity's start and end positions\n",
    "      token_start = None\n",
    "      token_end = None\n",
    "      for i, (start_offset, end_offset) in enumerate(offsets):\n",
    "          if start_offset <= start_char < end_offset:\n",
    "              token_start = i\n",
    "          if start_offset < end_char <= end_offset:\n",
    "              token_end = i\n",
    "              break\n",
    "      if token_start is not None and token_end is not None:\n",
    "          for i in range(token_start, token_end + 1):\n",
    "            if i == token_start:\n",
    "                labels[i] = label2id[\"B-\"+named_entity['labels'][0]]\n",
    "            else:\n",
    "                labels[i] = label2id[\"I-\"+named_entity['labels'][0]]\n",
    "\n",
    "  tokens['labels'] = labels\n",
    "  return tokens"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def transform_dataset_entry(entry):\n",
    "  text = entry['data']['text']\n",
    "  named_entities = [r['value'] for r in entry['annotations'][0]['result']]\n",
    "  return tokenize_and_ner(text, named_entities)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(\"./NER_TRAIN_JUDGEMENT.json\", 'r') as f:\n",
    "  train_data = json.load(f)\n",
    "\n",
    "with open(\"./NER_DEV/NER_DEV_JUDGEMENT.json\", 'r') as f:\n",
    "  valid_data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_dict = {\n",
    "    'train': train_data,\n",
    "    'valid': valid_data\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_dict = {part:pd.DataFrame([transform_dataset_entry(entry) for entry in dataset]) for part, dataset in dataset_dict.items()}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': Dataset.from_pandas(dataset_dict['train']),\n",
    "    'valid': Dataset.from_pandas(dataset_dict['valid'])\n",
    "})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, Trainer, TrainingArguments\n",
    "from datasets import load_metric\n",
    "\n",
    "import evaluate\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=29, id2label=id2label, label2id=label2id\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    true_predictions = [\n",
    "        [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [id2label[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = seqeval.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_law_ner_model\",\n",
    "    learning_rate=1e-5,\n",
    "    per_device_train_batch_size=48,\n",
    "    per_device_eval_batch_size=48,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_dict[\"train\"],\n",
    "    eval_dataset=dataset_dict[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
